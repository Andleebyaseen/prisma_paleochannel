{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net notebook for Palaeochannels dataset\n",
    "The input for training:\n",
    "\n",
    "-geojson file of:\n",
    "    train tiles\n",
    "    train area\n",
    "    validation(test) tiles\n",
    "    validation(test) area \n",
    "    ground truth\n",
    "\n",
    "- tif file of:\n",
    "    image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "workdir = Path(os.getenv(\"WORKDIR\", '..'))\n",
    "scratchdir = Path(os.getenv(\"SCRATCHDIR\", '..')) #checkpoint location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from segmentation_models_pytorch.decoders.unet import Unet\n",
    "from torchgeo.models.resnet import ResNet50_Weights, resnet50\n",
    "from torchinfo import summary\n",
    "import sys\n",
    "sys.path.append(str(workdir))\n",
    "from esa_cls_palaeo.dataset import SingleRasterPalaeochannelDataset\n",
    "\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "import kornia.augmentation as K\n",
    "\n",
    "from typing import Any\n",
    "from lightning.pytorch.utilities.types import STEP_OUTPUT\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import segmentation_models_pytorch as smp\n",
    "import os\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "from lightning.pytorch import LightningModule\n",
    "from segmentation_models_pytorch.decoders.unet import Unet\n",
    "from torchgeo.models.resnet import ResNet50_Weights, resnet50\n",
    "from torchmetrics.classification import BinaryJaccardIndex, BinaryPrecision, BinaryRecall, BinaryPrecisionRecallCurve\n",
    "\n",
    "from torchvision.utils import make_grid, draw_segmentation_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /home/vscode/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n",
      "100%|██████████| 97.8M/97.8M [00:01<00:00, 94.7MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNetEncoder                            [32, 3, 256, 256]         --\n",
       "├─Conv2d: 1-1                            [32, 64, 128, 128]        9,408\n",
       "├─BatchNorm2d: 1-2                       [32, 64, 128, 128]        128\n",
       "├─ReLU: 1-3                              [32, 64, 128, 128]        --\n",
       "├─MaxPool2d: 1-4                         [32, 64, 64, 64]          --\n",
       "├─Sequential: 1-5                        [32, 256, 64, 64]         --\n",
       "│    └─Bottleneck: 2-1                   [32, 256, 64, 64]         --\n",
       "│    │    └─Conv2d: 3-1                  [32, 64, 64, 64]          4,096\n",
       "│    │    └─BatchNorm2d: 3-2             [32, 64, 64, 64]          128\n",
       "│    │    └─ReLU: 3-3                    [32, 64, 64, 64]          --\n",
       "│    │    └─Conv2d: 3-4                  [32, 64, 64, 64]          36,864\n",
       "│    │    └─BatchNorm2d: 3-5             [32, 64, 64, 64]          128\n",
       "│    │    └─ReLU: 3-6                    [32, 64, 64, 64]          --\n",
       "│    │    └─Conv2d: 3-7                  [32, 256, 64, 64]         16,384\n",
       "│    │    └─BatchNorm2d: 3-8             [32, 256, 64, 64]         512\n",
       "│    │    └─Sequential: 3-9              [32, 256, 64, 64]         16,896\n",
       "│    │    └─ReLU: 3-10                   [32, 256, 64, 64]         --\n",
       "│    └─Bottleneck: 2-2                   [32, 256, 64, 64]         --\n",
       "│    │    └─Conv2d: 3-11                 [32, 64, 64, 64]          16,384\n",
       "│    │    └─BatchNorm2d: 3-12            [32, 64, 64, 64]          128\n",
       "│    │    └─ReLU: 3-13                   [32, 64, 64, 64]          --\n",
       "│    │    └─Conv2d: 3-14                 [32, 64, 64, 64]          36,864\n",
       "│    │    └─BatchNorm2d: 3-15            [32, 64, 64, 64]          128\n",
       "│    │    └─ReLU: 3-16                   [32, 64, 64, 64]          --\n",
       "│    │    └─Conv2d: 3-17                 [32, 256, 64, 64]         16,384\n",
       "│    │    └─BatchNorm2d: 3-18            [32, 256, 64, 64]         512\n",
       "│    │    └─ReLU: 3-19                   [32, 256, 64, 64]         --\n",
       "│    └─Bottleneck: 2-3                   [32, 256, 64, 64]         --\n",
       "│    │    └─Conv2d: 3-20                 [32, 64, 64, 64]          16,384\n",
       "│    │    └─BatchNorm2d: 3-21            [32, 64, 64, 64]          128\n",
       "│    │    └─ReLU: 3-22                   [32, 64, 64, 64]          --\n",
       "│    │    └─Conv2d: 3-23                 [32, 64, 64, 64]          36,864\n",
       "│    │    └─BatchNorm2d: 3-24            [32, 64, 64, 64]          128\n",
       "│    │    └─ReLU: 3-25                   [32, 64, 64, 64]          --\n",
       "│    │    └─Conv2d: 3-26                 [32, 256, 64, 64]         16,384\n",
       "│    │    └─BatchNorm2d: 3-27            [32, 256, 64, 64]         512\n",
       "│    │    └─ReLU: 3-28                   [32, 256, 64, 64]         --\n",
       "├─Sequential: 1-6                        [32, 512, 32, 32]         --\n",
       "│    └─Bottleneck: 2-4                   [32, 512, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-29                 [32, 128, 64, 64]         32,768\n",
       "│    │    └─BatchNorm2d: 3-30            [32, 128, 64, 64]         256\n",
       "│    │    └─ReLU: 3-31                   [32, 128, 64, 64]         --\n",
       "│    │    └─Conv2d: 3-32                 [32, 128, 32, 32]         147,456\n",
       "│    │    └─BatchNorm2d: 3-33            [32, 128, 32, 32]         256\n",
       "│    │    └─ReLU: 3-34                   [32, 128, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-35                 [32, 512, 32, 32]         65,536\n",
       "│    │    └─BatchNorm2d: 3-36            [32, 512, 32, 32]         1,024\n",
       "│    │    └─Sequential: 3-37             [32, 512, 32, 32]         132,096\n",
       "│    │    └─ReLU: 3-38                   [32, 512, 32, 32]         --\n",
       "│    └─Bottleneck: 2-5                   [32, 512, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-39                 [32, 128, 32, 32]         65,536\n",
       "│    │    └─BatchNorm2d: 3-40            [32, 128, 32, 32]         256\n",
       "│    │    └─ReLU: 3-41                   [32, 128, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-42                 [32, 128, 32, 32]         147,456\n",
       "│    │    └─BatchNorm2d: 3-43            [32, 128, 32, 32]         256\n",
       "│    │    └─ReLU: 3-44                   [32, 128, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-45                 [32, 512, 32, 32]         65,536\n",
       "│    │    └─BatchNorm2d: 3-46            [32, 512, 32, 32]         1,024\n",
       "│    │    └─ReLU: 3-47                   [32, 512, 32, 32]         --\n",
       "│    └─Bottleneck: 2-6                   [32, 512, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-48                 [32, 128, 32, 32]         65,536\n",
       "│    │    └─BatchNorm2d: 3-49            [32, 128, 32, 32]         256\n",
       "│    │    └─ReLU: 3-50                   [32, 128, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-51                 [32, 128, 32, 32]         147,456\n",
       "│    │    └─BatchNorm2d: 3-52            [32, 128, 32, 32]         256\n",
       "│    │    └─ReLU: 3-53                   [32, 128, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-54                 [32, 512, 32, 32]         65,536\n",
       "│    │    └─BatchNorm2d: 3-55            [32, 512, 32, 32]         1,024\n",
       "│    │    └─ReLU: 3-56                   [32, 512, 32, 32]         --\n",
       "│    └─Bottleneck: 2-7                   [32, 512, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-57                 [32, 128, 32, 32]         65,536\n",
       "│    │    └─BatchNorm2d: 3-58            [32, 128, 32, 32]         256\n",
       "│    │    └─ReLU: 3-59                   [32, 128, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-60                 [32, 128, 32, 32]         147,456\n",
       "│    │    └─BatchNorm2d: 3-61            [32, 128, 32, 32]         256\n",
       "│    │    └─ReLU: 3-62                   [32, 128, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-63                 [32, 512, 32, 32]         65,536\n",
       "│    │    └─BatchNorm2d: 3-64            [32, 512, 32, 32]         1,024\n",
       "│    │    └─ReLU: 3-65                   [32, 512, 32, 32]         --\n",
       "├─Sequential: 1-7                        [32, 1024, 16, 16]        --\n",
       "│    └─Bottleneck: 2-8                   [32, 1024, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-66                 [32, 256, 32, 32]         131,072\n",
       "│    │    └─BatchNorm2d: 3-67            [32, 256, 32, 32]         512\n",
       "│    │    └─ReLU: 3-68                   [32, 256, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-69                 [32, 256, 16, 16]         589,824\n",
       "│    │    └─BatchNorm2d: 3-70            [32, 256, 16, 16]         512\n",
       "│    │    └─ReLU: 3-71                   [32, 256, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-72                 [32, 1024, 16, 16]        262,144\n",
       "│    │    └─BatchNorm2d: 3-73            [32, 1024, 16, 16]        2,048\n",
       "│    │    └─Sequential: 3-74             [32, 1024, 16, 16]        526,336\n",
       "│    │    └─ReLU: 3-75                   [32, 1024, 16, 16]        --\n",
       "│    └─Bottleneck: 2-9                   [32, 1024, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-76                 [32, 256, 16, 16]         262,144\n",
       "│    │    └─BatchNorm2d: 3-77            [32, 256, 16, 16]         512\n",
       "│    │    └─ReLU: 3-78                   [32, 256, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-79                 [32, 256, 16, 16]         589,824\n",
       "│    │    └─BatchNorm2d: 3-80            [32, 256, 16, 16]         512\n",
       "│    │    └─ReLU: 3-81                   [32, 256, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-82                 [32, 1024, 16, 16]        262,144\n",
       "│    │    └─BatchNorm2d: 3-83            [32, 1024, 16, 16]        2,048\n",
       "│    │    └─ReLU: 3-84                   [32, 1024, 16, 16]        --\n",
       "│    └─Bottleneck: 2-10                  [32, 1024, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-85                 [32, 256, 16, 16]         262,144\n",
       "│    │    └─BatchNorm2d: 3-86            [32, 256, 16, 16]         512\n",
       "│    │    └─ReLU: 3-87                   [32, 256, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-88                 [32, 256, 16, 16]         589,824\n",
       "│    │    └─BatchNorm2d: 3-89            [32, 256, 16, 16]         512\n",
       "│    │    └─ReLU: 3-90                   [32, 256, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-91                 [32, 1024, 16, 16]        262,144\n",
       "│    │    └─BatchNorm2d: 3-92            [32, 1024, 16, 16]        2,048\n",
       "│    │    └─ReLU: 3-93                   [32, 1024, 16, 16]        --\n",
       "│    └─Bottleneck: 2-11                  [32, 1024, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-94                 [32, 256, 16, 16]         262,144\n",
       "│    │    └─BatchNorm2d: 3-95            [32, 256, 16, 16]         512\n",
       "│    │    └─ReLU: 3-96                   [32, 256, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-97                 [32, 256, 16, 16]         589,824\n",
       "│    │    └─BatchNorm2d: 3-98            [32, 256, 16, 16]         512\n",
       "│    │    └─ReLU: 3-99                   [32, 256, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-100                [32, 1024, 16, 16]        262,144\n",
       "│    │    └─BatchNorm2d: 3-101           [32, 1024, 16, 16]        2,048\n",
       "│    │    └─ReLU: 3-102                  [32, 1024, 16, 16]        --\n",
       "│    └─Bottleneck: 2-12                  [32, 1024, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-103                [32, 256, 16, 16]         262,144\n",
       "│    │    └─BatchNorm2d: 3-104           [32, 256, 16, 16]         512\n",
       "│    │    └─ReLU: 3-105                  [32, 256, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-106                [32, 256, 16, 16]         589,824\n",
       "│    │    └─BatchNorm2d: 3-107           [32, 256, 16, 16]         512\n",
       "│    │    └─ReLU: 3-108                  [32, 256, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-109                [32, 1024, 16, 16]        262,144\n",
       "│    │    └─BatchNorm2d: 3-110           [32, 1024, 16, 16]        2,048\n",
       "│    │    └─ReLU: 3-111                  [32, 1024, 16, 16]        --\n",
       "│    └─Bottleneck: 2-13                  [32, 1024, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-112                [32, 256, 16, 16]         262,144\n",
       "│    │    └─BatchNorm2d: 3-113           [32, 256, 16, 16]         512\n",
       "│    │    └─ReLU: 3-114                  [32, 256, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-115                [32, 256, 16, 16]         589,824\n",
       "│    │    └─BatchNorm2d: 3-116           [32, 256, 16, 16]         512\n",
       "│    │    └─ReLU: 3-117                  [32, 256, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-118                [32, 1024, 16, 16]        262,144\n",
       "│    │    └─BatchNorm2d: 3-119           [32, 1024, 16, 16]        2,048\n",
       "│    │    └─ReLU: 3-120                  [32, 1024, 16, 16]        --\n",
       "├─Sequential: 1-8                        [32, 2048, 8, 8]          --\n",
       "│    └─Bottleneck: 2-14                  [32, 2048, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-121                [32, 512, 16, 16]         524,288\n",
       "│    │    └─BatchNorm2d: 3-122           [32, 512, 16, 16]         1,024\n",
       "│    │    └─ReLU: 3-123                  [32, 512, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-124                [32, 512, 8, 8]           2,359,296\n",
       "│    │    └─BatchNorm2d: 3-125           [32, 512, 8, 8]           1,024\n",
       "│    │    └─ReLU: 3-126                  [32, 512, 8, 8]           --\n",
       "│    │    └─Conv2d: 3-127                [32, 2048, 8, 8]          1,048,576\n",
       "│    │    └─BatchNorm2d: 3-128           [32, 2048, 8, 8]          4,096\n",
       "│    │    └─Sequential: 3-129            [32, 2048, 8, 8]          2,101,248\n",
       "│    │    └─ReLU: 3-130                  [32, 2048, 8, 8]          --\n",
       "│    └─Bottleneck: 2-15                  [32, 2048, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-131                [32, 512, 8, 8]           1,048,576\n",
       "│    │    └─BatchNorm2d: 3-132           [32, 512, 8, 8]           1,024\n",
       "│    │    └─ReLU: 3-133                  [32, 512, 8, 8]           --\n",
       "│    │    └─Conv2d: 3-134                [32, 512, 8, 8]           2,359,296\n",
       "│    │    └─BatchNorm2d: 3-135           [32, 512, 8, 8]           1,024\n",
       "│    │    └─ReLU: 3-136                  [32, 512, 8, 8]           --\n",
       "│    │    └─Conv2d: 3-137                [32, 2048, 8, 8]          1,048,576\n",
       "│    │    └─BatchNorm2d: 3-138           [32, 2048, 8, 8]          4,096\n",
       "│    │    └─ReLU: 3-139                  [32, 2048, 8, 8]          --\n",
       "│    └─Bottleneck: 2-16                  [32, 2048, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-140                [32, 512, 8, 8]           1,048,576\n",
       "│    │    └─BatchNorm2d: 3-141           [32, 512, 8, 8]           1,024\n",
       "│    │    └─ReLU: 3-142                  [32, 512, 8, 8]           --\n",
       "│    │    └─Conv2d: 3-143                [32, 512, 8, 8]           2,359,296\n",
       "│    │    └─BatchNorm2d: 3-144           [32, 512, 8, 8]           1,024\n",
       "│    │    └─ReLU: 3-145                  [32, 512, 8, 8]           --\n",
       "│    │    └─Conv2d: 3-146                [32, 2048, 8, 8]          1,048,576\n",
       "│    │    └─BatchNorm2d: 3-147           [32, 2048, 8, 8]          4,096\n",
       "│    │    └─ReLU: 3-148                  [32, 2048, 8, 8]          --\n",
       "==========================================================================================\n",
       "Total params: 23,508,032\n",
       "Trainable params: 23,508,032\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 170.83\n",
       "==========================================================================================\n",
       "Input size (MB): 25.17\n",
       "Forward/backward pass size (MB): 7432.31\n",
       "Params size (MB): 94.03\n",
       "Estimated Total Size (MB): 7551.50\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Unet(encoder_name=\"resnet50\", in_channels=3)\n",
    "summary(model.encoder, input_size=(32, 3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "Unet                                          [32, 1, 256, 256]         --\n",
       "├─ResNetEncoder: 1-1                          [32, 3, 256, 256]         --\n",
       "│    └─Conv2d: 2-1                            [32, 64, 128, 128]        9,408\n",
       "│    └─BatchNorm2d: 2-2                       [32, 64, 128, 128]        128\n",
       "│    └─ReLU: 2-3                              [32, 64, 128, 128]        --\n",
       "│    └─MaxPool2d: 2-4                         [32, 64, 64, 64]          --\n",
       "│    └─Sequential: 2-5                        [32, 256, 64, 64]         --\n",
       "│    │    └─Bottleneck: 3-1                   [32, 256, 64, 64]         75,008\n",
       "│    │    └─Bottleneck: 3-2                   [32, 256, 64, 64]         70,400\n",
       "│    │    └─Bottleneck: 3-3                   [32, 256, 64, 64]         70,400\n",
       "│    └─Sequential: 2-6                        [32, 512, 32, 32]         --\n",
       "│    │    └─Bottleneck: 3-4                   [32, 512, 32, 32]         379,392\n",
       "│    │    └─Bottleneck: 3-5                   [32, 512, 32, 32]         280,064\n",
       "│    │    └─Bottleneck: 3-6                   [32, 512, 32, 32]         280,064\n",
       "│    │    └─Bottleneck: 3-7                   [32, 512, 32, 32]         280,064\n",
       "│    └─Sequential: 2-7                        [32, 1024, 16, 16]        --\n",
       "│    │    └─Bottleneck: 3-8                   [32, 1024, 16, 16]        1,512,448\n",
       "│    │    └─Bottleneck: 3-9                   [32, 1024, 16, 16]        1,117,184\n",
       "│    │    └─Bottleneck: 3-10                  [32, 1024, 16, 16]        1,117,184\n",
       "│    │    └─Bottleneck: 3-11                  [32, 1024, 16, 16]        1,117,184\n",
       "│    │    └─Bottleneck: 3-12                  [32, 1024, 16, 16]        1,117,184\n",
       "│    │    └─Bottleneck: 3-13                  [32, 1024, 16, 16]        1,117,184\n",
       "│    └─Sequential: 2-8                        [32, 2048, 8, 8]          --\n",
       "│    │    └─Bottleneck: 3-14                  [32, 2048, 8, 8]          6,039,552\n",
       "│    │    └─Bottleneck: 3-15                  [32, 2048, 8, 8]          4,462,592\n",
       "│    │    └─Bottleneck: 3-16                  [32, 2048, 8, 8]          4,462,592\n",
       "├─UnetDecoder: 1-2                            [32, 16, 256, 256]        --\n",
       "│    └─Identity: 2-9                          [32, 2048, 8, 8]          --\n",
       "│    └─ModuleList: 2-10                       --                        --\n",
       "│    │    └─DecoderBlock: 3-17                [32, 256, 16, 16]         7,668,736\n",
       "│    │    └─DecoderBlock: 3-18                [32, 128, 32, 32]         1,032,704\n",
       "│    │    └─DecoderBlock: 3-19                [32, 64, 64, 64]          258,304\n",
       "│    │    └─DecoderBlock: 3-20                [32, 32, 128, 128]        46,208\n",
       "│    │    └─DecoderBlock: 3-21                [32, 16, 256, 256]        6,976\n",
       "├─SegmentationHead: 1-3                       [32, 1, 256, 256]         --\n",
       "│    └─Conv2d: 2-11                           [32, 1, 256, 256]         145\n",
       "│    └─Identity: 2-12                         [32, 1, 256, 256]         --\n",
       "│    └─Activation: 2-13                       [32, 1, 256, 256]         --\n",
       "│    │    └─Identity: 3-22                    [32, 1, 256, 256]         --\n",
       "===============================================================================================\n",
       "Total params: 32,521,105\n",
       "Trainable params: 32,521,105\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 340.25\n",
       "===============================================================================================\n",
       "Input size (MB): 25.17\n",
       "Forward/backward pass size (MB): 9529.46\n",
       "Params size (MB): 130.08\n",
       "Estimated Total Size (MB): 9684.71\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_size=(32, 3, 256, 256))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading encoder's weights from TorchGeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets build! 2472 training tiles, 255 testing tiles.\n"
     ]
    }
   ],
   "source": [
    "train_tiles_df = gpd.read_file(workdir / 'data/AREA_TRAIN_TEST/TrainTiles_CLS_UTM.geojson')\n",
    "train_aoi_df = gpd.read_file(workdir / 'data/AREA_TRAIN_TEST/TrainSet_CLS_UTM.geojson')\n",
    "test_tiles_df = gpd.read_file(workdir / 'data/AREA_TRAIN_TEST/TestTiles_CLS_UTM.geojson')\n",
    "test_aoi_df = gpd.read_file(workdir / 'data/AREA_TRAIN_TEST/TestSet_CLS_UTM.geojson')\n",
    "\n",
    "spring_tif_path = workdir / \"data/GEE/three_seasons_median_2022/spring_march-april_median.tif\"\n",
    "spring_features_df = gpd.read_file(workdir / 'data/FEATURES/spring_V2.geojson')\n",
    "summer_tif_path = workdir / \"data/GEE/three_seasons_median_2022/summer_july-aug_median.tif\"\n",
    "summer_features_df = gpd.read_file(workdir / 'data/FEATURES/summer_V2.geojson')\n",
    "winter_tif_path = workdir / \"data/GEE/three_seasons_median_2022/winter_nov-dec_median.tif\"\n",
    "winter_features_df = gpd.read_file(workdir / 'data/FEATURES/winter_V2.geojson')\n",
    "\n",
    "\n",
    "\n",
    "spring_train_dataset = SingleRasterPalaeochannelDataset(train_tiles_df, spring_tif_path, spring_features_df, train_aoi_df)\n",
    "summer_train_dataset = SingleRasterPalaeochannelDataset(train_tiles_df, summer_tif_path, summer_features_df, train_aoi_df)\n",
    "winter_train_dataset = SingleRasterPalaeochannelDataset(train_tiles_df, winter_tif_path, winter_features_df, train_aoi_df)\n",
    "\n",
    "spring_test_dataset = SingleRasterPalaeochannelDataset(test_tiles_df, spring_tif_path, spring_features_df, test_aoi_df)\n",
    "summer_test_dataset = SingleRasterPalaeochannelDataset(test_tiles_df, summer_tif_path, summer_features_df, test_aoi_df)\n",
    "winter_test_dataset = SingleRasterPalaeochannelDataset(test_tiles_df, winter_tif_path, winter_features_df, test_aoi_df)\n",
    "\n",
    "full_train_dataset = ConcatDataset([spring_train_dataset, summer_train_dataset, winter_train_dataset])\n",
    "full_test_dataset = ConcatDataset([spring_test_dataset, summer_test_dataset, winter_test_dataset])\n",
    "print(f\"Datasets build! {len(full_train_dataset)} training tiles, {len(full_test_dataset)} testing tiles.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightningModule adapted from Andaleeb's notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "from lightning.pytorch.callbacks.callback import Callback\n",
    "from lightning.pytorch.utilities.types import OptimizerLRScheduler\n",
    "from lightning.pytorch.callbacks import StochasticWeightAveraging\n",
    "\n",
    "class PalaeochannelRGBExperimentModule(LightningModule):\n",
    "    def __init__(self, *args: Any, \n",
    "                 learning_rate: float = 1.0e-3, \n",
    "                 logits_threshold: float = 0.1, \n",
    "                 weight_decay: float = 1.0e-3, \n",
    "                 clip_stds: float = 2.5, \n",
    "                 swa_lrs = 1e-3,\n",
    "                 swa_epoch_start = 20,\n",
    "                 tversky_gamma: float = 1.0, \n",
    "                 tversky_alpha: float = 0.4, \n",
    "                 tversky_beta: float = 0.6,\n",
    "                 model_tag: str = 'unet-resnet50-sen2-rgb-moco', # Consider a smarter tagging strategy.\n",
    "                 **kwargs: Any) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # Model creation and weights loading\n",
    "        if model_tag == 'unet-resnet50-sen2-rgb-moco':\n",
    "            self.model = Unet(encoder_name=\"resnet50\", in_channels=3)\n",
    "            encoder_model = resnet50(weights=ResNet50_Weights.SENTINEL2_RGB_MOCO)\n",
    "            self.model.encoder.load_state_dict(encoder_model.state_dict())\n",
    "        else:\n",
    "            self.model = Unet(encoder_name=\"mit_b5\", decoder_attention_type='scse', in_channels=3)\n",
    "        \n",
    "        # TverskyLoss Loss function \n",
    "        # self.loss_criterion = smp.losses.TverskyLoss(mode=\"binary\", \n",
    "        #                                              gamma=self.hparams.tversky_gamma, \n",
    "        #                                              alpha=self.hparams.tversky_alpha, \n",
    "        #                                              beta=self.hparams.tversky_beta,)\n",
    "        # DiceLoss Loss function\n",
    "        self.loss_criterion = smp.losses.DiceLoss(mode='binary')\n",
    "        # Augmentations\n",
    "        self.spatial_augmentation_pipeline = K.AugmentationSequential(\n",
    "            K.RandomHorizontalFlip(p=0.5),\n",
    "            K.RandomVerticalFlip(p=0.5),\n",
    "            data_keys=[\"input\", \"mask\"]  # Apply to both image and mask\n",
    "        )\n",
    "        self.color_augmentation_pipeline = K.AugmentationSequential(\n",
    "            # K.ColorJitter(brightness=0.2, contrast=0.3, saturation=0.2, hue=0.1),\n",
    "            data_keys=[\"input\"]  # Apply to images only\n",
    "        )\n",
    "        # Metrics creation\n",
    "        self.train_iou = BinaryJaccardIndex(threshold=self.hparams.logits_threshold)\n",
    "        self.train_precision = BinaryPrecision(threshold=self.hparams.logits_threshold)\n",
    "        self.train_recall = BinaryRecall(threshold=self.hparams.logits_threshold)\n",
    "        \n",
    "        self.validation_iou = BinaryJaccardIndex(threshold=self.hparams.logits_threshold)\n",
    "        self.validation_precision = BinaryPrecision(threshold=self.hparams.logits_threshold)\n",
    "        self.validation_recall = BinaryRecall(threshold=self.hparams.logits_threshold)\n",
    "        \n",
    "        self.validation_prec_rec_curve = BinaryPrecisionRecallCurve(thresholds=20)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def configure_callbacks(self) -> Sequence[Callback] | Callback:\n",
    "        swa = StochasticWeightAveraging(swa_lrs=self.hparams.swa_lrs, \n",
    "                                        swa_epoch_start=self.hparams.swa_epoch_start)\n",
    "        return [swa]\n",
    "    \n",
    "    def configure_optimizers(self) -> OptimizerLRScheduler:\n",
    "        return optim.Adam(self.model.parameters(),\n",
    "                          lr=self.hparams.learning_rate, \n",
    "                          weight_decay=self.hparams.weight_decay)\n",
    "\n",
    "    def on_after_batch_transfer(self, batch: Any, dataloader_idx: int) -> Any:\n",
    "        # Fix batch types.\n",
    "        images = batch['image'].float()\n",
    "        masks = batch['mask'].float().unsqueeze(1)\n",
    "        \n",
    "        # Finish raster to tensor conversion\n",
    "        images = torch.movedim(images, -1, -3)\n",
    "        images = images[:, [3, 2, 1], :, :] # Select RGB bands\n",
    "         \n",
    "        # Clip each tile bands using local statistics.\n",
    "        from torch.masked import masked_tensor\n",
    "        masked_images = masked_tensor(images, images > 0.0)\n",
    "        images_mean = masked_images.mean(dim=(2, 3), keepdim=True).get_data()\n",
    "        images_std = masked_images.std(dim=(2, 3), keepdim=True).get_data()\n",
    "        images_max_clip = images_mean + self.hparams.clip_stds * images_std\n",
    "        images_min_clip = images_mean - self.hparams.clip_stds * images_std\n",
    "        images = (images - images_min_clip) / (images_max_clip - images_min_clip)\n",
    "        \n",
    "        # Data augmentation during training.\n",
    "        if self.trainer.training: \n",
    "            images = self.color_augmentation_pipeline(images)\n",
    "            images, masks = self.spatial_augmentation_pipeline(images, masks)\n",
    "        \n",
    "        batch['image'] = images\n",
    "        batch['mask'] = masks.squeeze(1).int()\n",
    "        return super().on_after_batch_transfer(batch, dataloader_idx)\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        x = batch['image']\n",
    "        # Do not propagate gradient to the encoder network for now.\n",
    "        with torch.no_grad():\n",
    "            features = self.model.encoder(x)\n",
    "        decoder_output = self.model.decoder(*features)\n",
    "\n",
    "        return self.model.segmentation_head(decoder_output)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx, *args: Any, **kwargs: Any) -> STEP_OUTPUT:\n",
    "        logits = self.forward(batch).squeeze()\n",
    "        loss = self.loss_criterion(logits, batch['mask'])\n",
    "        \n",
    "        # Update metrics\n",
    "        self.train_iou(logits, batch['mask'])\n",
    "        self.train_precision(logits, batch['mask'])\n",
    "        self.train_recall(logits, batch['mask'])\n",
    "        \n",
    "        # Log step loss\n",
    "        batch_size = batch['image'].shape[0]\n",
    "        self.log('train/loss', loss, on_epoch=True, on_step=True, batch_size=batch_size)\n",
    "        \n",
    "        # Log batch output (images)\n",
    "        if batch_idx == 0:\n",
    "            self.log_batch_output(batch, logits)\n",
    "            \n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        # Log metrics\n",
    "        self.log('train/iou', self.train_iou)\n",
    "        self.log('train/precision', self.train_precision)\n",
    "        self.log('train/recall', self.train_recall)\n",
    "        return super().on_train_epoch_end()\n",
    "    \n",
    "    def log_batch_output(self, batch, logits):\n",
    "        if isinstance(self.logger, TensorBoardLogger):\n",
    "            stage = 'none'\n",
    "            if self.trainer.validating:\n",
    "                stage = 'validation'\n",
    "            if self.trainer.training:\n",
    "                stage = 'train'\n",
    "            mask = batch['mask'].unsqueeze(1)\n",
    "            segmentation_mask = logits.unsqueeze(1) > self.hparams.logits_threshold\n",
    "            summary_writer: SummaryWriter = self.logger.experiment\n",
    "            summary_writer.add_images(f'{stage}/image', batch['image'], global_step=self.trainer.global_step)\n",
    "            summary_writer.add_images(f'{stage}/mask', mask * 255, global_step=self.trainer.global_step)\n",
    "            summary_writer.add_images(f'{stage}/logits', segmentation_mask, global_step=self.trainer.global_step)\n",
    "            \n",
    "            \n",
    "    # The same thing as the training step but on validation objects.\n",
    "    def validation_step(self, batch, batch_idx, *args: Any, **kwargs: Any) -> STEP_OUTPUT:\n",
    "        logits = self.forward(batch).squeeze()\n",
    "        print(logits.shape)\n",
    "        print('batch[mask]',batch['mask'].shape)\n",
    "        loss = self.loss_criterion(logits, batch['mask'])\n",
    "        \n",
    "        self.validation_iou(logits, batch['mask'])\n",
    "        self.validation_precision(logits, batch['mask'])\n",
    "        self.validation_recall(logits, batch['mask'])\n",
    "        \n",
    "        self.validation_prec_rec_curve(logits, batch['mask'])\n",
    "        \n",
    "        batch_size = batch['image'].shape[0]\n",
    "        self.log('validation/loss', loss, on_epoch=True, batch_size=batch_size)\n",
    "        if batch_idx == 0:\n",
    "            self.log_batch_output(batch, logits)\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "    def on_validation_epoch_end(self) -> None:\n",
    "        self.log('validation/iou', self.validation_iou)\n",
    "        self.log('validation/precision', self.validation_precision)\n",
    "        self.log('validation/recall', self.validation_recall)\n",
    "        \n",
    "        # Log the precision recall curve!\n",
    "        if isinstance(self.logger, TensorBoardLogger):\n",
    "            summary_writer: SummaryWriter = self.logger.experiment\n",
    "            fig_, ax_ = self.validation_prec_rec_curve.plot(score=True)\n",
    "            summary_writer.add_figure('validation/prec_rec_curve', figure=fig_, global_step=self.trainer.global_step)\n",
    "            \n",
    "        return super().on_validation_epoch_end()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader = DataLoader(dataset=full_train_dataset, \n",
    "                          batch_size=16, \n",
    "                          num_workers=16, \n",
    "                          prefetch_factor=16, \n",
    "                          pin_memory=True, \n",
    "                          persistent_workers=True, \n",
    "                          shuffle=True)\n",
    "val_loader = DataLoader(dataset=full_test_dataset, \n",
    "                        batch_size=16, \n",
    "                        num_workers=16, \n",
    "                        prefetch_factor=16, \n",
    "                        pin_memory=True, \n",
    "                        persistent_workers=True, \n",
    "                        shuffle=True) # Consider shuffling the \"full_test_dataset\" in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/qubvel/segmentation_models.pytorch/releases/download/v0.0.2/mit_b5.pth\" to /home/vscode/.cache/torch/hub/checkpoints/mit_b5.pth\n",
      "100%|██████████| 313M/313M [00:07<00:00, 43.2MB/s] \n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from lightning import Trainer\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "lightning_module = PalaeochannelRGBExperimentModule(model_tag='mit_b5')\n",
    "logs_dir = scratchdir / 'run_logs_test'\n",
    "logger = TensorBoardLogger(name='dice-headonly-image_clip-imagenet-mit_b5-median', save_dir=logs_dir)\n",
    "checkpointing = ModelCheckpoint(filename='epoch={epoch}-val_iou={validation/iou:.8f}', \n",
    "                                auto_insert_metric_name=False, \n",
    "                                monitor='validation/iou', \n",
    "                                mode='max', \n",
    "                                save_top_k=2, \n",
    "                                save_last=True)\n",
    "trainer = Trainer(accelerator='gpu', devices=[0], log_every_n_steps=5, logger=logger, callbacks=[checkpointing])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/lightning/pytorch/loops/utilities.py:73: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "Missing logger folder: ../run_logs_test/dice-headonly-image_clip-imagenet-mit_b5-median\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "   | Name                          | Type                       | Params\n",
      "------------------------------------------------------------------------------\n",
      "0  | model                         | Unet                       | 84.8 M\n",
      "1  | loss_criterion                | DiceLoss                   | 0     \n",
      "2  | spatial_augmentation_pipeline | AugmentationSequential     | 0     \n",
      "3  | color_augmentation_pipeline   | AugmentationSequential     | 0     \n",
      "4  | train_iou                     | BinaryJaccardIndex         | 0     \n",
      "5  | train_precision               | BinaryPrecision            | 0     \n",
      "6  | train_recall                  | BinaryRecall               | 0     \n",
      "7  | validation_iou                | BinaryJaccardIndex         | 0     \n",
      "8  | validation_precision          | BinaryPrecision            | 0     \n",
      "9  | validation_recall             | BinaryRecall               | 0     \n",
      "10 | validation_prec_rec_curve     | BinaryPrecisionRecallCurve | 0     \n",
      "------------------------------------------------------------------------------\n",
      "84.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "84.8 M    Total params\n",
      "339.396   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:492: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/masked/maskedtensor/core.py:156: UserWarning: The PyTorch API of MaskedTensors is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.masked module for further information about the project.\n",
      "  warnings.warn((\"The PyTorch API of MaskedTensors is in prototype stage \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 256, 256])\n",
      "batch[mask] torch.Size([16, 256, 256])\n",
      "Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:02<00:02,  0.37it/s]torch.Size([16, 256, 256])\n",
      "batch[mask] torch.Size([16, 256, 256])\n",
      "Epoch 0:   0%|          | 0/155 [00:00<?, ?it/s]                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(lightning_module, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esa_cls_palaeo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
