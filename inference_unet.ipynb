{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET working Directory of the code\n",
    "import os\n",
    "workdir = os.path.abspath(os.path.join(os.getcwd(), '..'))  # Set workdir to the parent directory (Paleo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from pathlib import Path\n",
    "from segmentation_models_pytorch.decoders.unet import Unet\n",
    "from torchinfo import summary\n",
    "\n",
    "import sys\n",
    "sys.path.append(str(workdir))\n",
    "\n",
    "from esa_cls_palaeo.dataset import SingleRasterPalaeochannelDataset\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "import kornia.augmentation as K\n",
    "\n",
    "from typing import Any\n",
    "from lightning.pytorch.utilities.types import STEP_OUTPUT\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import segmentation_models_pytorch as smp\n",
    "import os\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "from lightning.pytorch import LightningModule\n",
    "from segmentation_models_pytorch.decoders.unet import Unet\n",
    "from torchgeo.models.resnet import ResNet50_Weights, resnet50\n",
    "import torchvision.models as models\n",
    "from torchmetrics.classification import BinaryJaccardIndex, BinaryPrecision, BinaryRecall, BinaryPrecisionRecallCurve\n",
    "\n",
    "from torchvision.utils import make_grid, draw_segmentation_masks\n",
    "from PIL import Image\n",
    "import rasterio as rio\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.plot import reshape_as_image\n",
    "from torch.masked import masked_tensor\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from rasterio.transform import from_origin\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the image for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### SET variables\n",
    "# Path_to_folder_images\n",
    "images_path = \"/Images/\"\n",
    "\n",
    "month= \"05_2023/\" # change \n",
    "\n",
    "test_img_folder = Path(images_path + month + \"output_raster_tiles\")\n",
    "test_mask_folder = Path(images_path + month + \"output_mask_tiles\")\n",
    "\n",
    "print(test_img_folder)\n",
    "print(test_mask_folder)\n",
    "\n",
    "# set output path \n",
    "save_output = True\n",
    "\n",
    "output_path = Path(images_path + month + \"Unet_inference_tiles\")\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint path\n",
    "chkp= \"checkpoint path\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model\n",
    "model = Unet(encoder_name='resnet50', in_channels=3)\n",
    "summary(model.encoder, input_size=(32, 3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "from lightning.pytorch.callbacks.callback import Callback\n",
    "from lightning.pytorch.utilities.types import OptimizerLRScheduler\n",
    "from lightning.pytorch.callbacks import StochasticWeightAveraging\n",
    "\n",
    "class PalaeochannelRGBExperimentModule(LightningModule):\n",
    "    def __init__(self, *args: Any, \n",
    "                 learning_rate: float = 1.0e-3, \n",
    "                 logits_threshold: float = 0.1, \n",
    "                 weight_decay: float = 1.0e-3, \n",
    "                 clip_stds: float = 2.5, \n",
    "                 swa_lrs = 1e-3,\n",
    "                 swa_epoch_start = 20,\n",
    "                 tversky_gamma: float = 1.0, \n",
    "                 tversky_alpha: float = 0.4, \n",
    "                 tversky_beta: float = 0.6,\n",
    "                 model_tag: str = 'unet-resnet50-sen2-rgb-moco', # Consider a smarter tagging strategy.\n",
    "                 **kwargs: Any) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # Model creation and weights loading\n",
    "        if model_tag == 'unet-resnet50-sen2-rgb-moco':\n",
    "            self.model = Unet(encoder_name=\"resnet50\", in_channels=3)\n",
    "            encoder_model = resnet50(weights=ResNet50_Weights.SENTINEL2_RGB_MOCO)\n",
    "            self.model.encoder.load_state_dict(encoder_model.state_dict())\n",
    "        else:\n",
    "            self.model = Unet(encoder_name=\"mit_b5\", decoder_attention_type='scse', in_channels=3)\n",
    "        \n",
    "        # Loss function\n",
    "        # self.loss_criterion = smp.losses.TverskyLoss(mode=\"binary\", \n",
    "        #                                              gamma=self.hparams.tversky_gamma, \n",
    "        #                                              alpha=self.hparams.tversky_alpha, \n",
    "        #                                              beta=self.hparams.tversky_beta,)\n",
    "            \n",
    "        self.loss_criterion = smp.losses.DiceLoss(mode='binary')\n",
    "        # Augmentations\n",
    "        self.spatial_augmentation_pipeline = K.AugmentationSequential(\n",
    "            K.RandomHorizontalFlip(p=0.5),\n",
    "            K.RandomVerticalFlip(p=0.5),\n",
    "            data_keys=[\"input\", \"mask\"]  # Apply to both image and mask\n",
    "        )\n",
    "        self.color_augmentation_pipeline = K.AugmentationSequential(\n",
    "            # K.ColorJitter(brightness=0.2, contrast=0.3, saturation=0.2, hue=0.1),\n",
    "            data_keys=[\"input\"]  # Apply to images only\n",
    "        )\n",
    "        # Metrics creation\n",
    "        self.train_iou = BinaryJaccardIndex(threshold=self.hparams.logits_threshold)\n",
    "        self.train_precision = BinaryPrecision(threshold=self.hparams.logits_threshold)\n",
    "        self.train_recall = BinaryRecall(threshold=self.hparams.logits_threshold)\n",
    "        \n",
    "        self.validation_iou = BinaryJaccardIndex(threshold=self.hparams.logits_threshold)\n",
    "        self.validation_precision = BinaryPrecision(threshold=self.hparams.logits_threshold)\n",
    "        self.validation_recall = BinaryRecall(threshold=self.hparams.logits_threshold)\n",
    "        \n",
    "        self.validation_prec_rec_curve = BinaryPrecisionRecallCurve(thresholds=20)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def configure_callbacks(self) -> Sequence[Callback] | Callback:\n",
    "        swa = StochasticWeightAveraging(swa_lrs=self.hparams.swa_lrs, \n",
    "                                        swa_epoch_start=self.hparams.swa_epoch_start)\n",
    "        return [swa]\n",
    "    \n",
    "    def configure_optimizers(self) -> OptimizerLRScheduler:\n",
    "        return optim.Adam(self.model.parameters(),\n",
    "                          lr=self.hparams.learning_rate, \n",
    "                          weight_decay=self.hparams.weight_decay)\n",
    "\n",
    "    def on_after_batch_transfer(self, batch: Any, dataloader_idx: int) -> Any:\n",
    "        # Fix batch types.\n",
    "        images = batch['image'].float()\n",
    "        masks = batch['mask'].float().unsqueeze(1)\n",
    "        \n",
    "        # Finish raster to tensor conversion\n",
    "        images = torch.movedim(images, -1, -3)\n",
    "        images = images[:, [3, 2, 1], :, :] # Select RGB bands\n",
    "         \n",
    "        # Clip each tile bands using local statistics.\n",
    "        from torch.masked import masked_tensor\n",
    "        masked_images = masked_tensor(images, images > 0.0)\n",
    "        images_mean = masked_images.mean(dim=(2, 3), keepdim=True).get_data()\n",
    "        images_std = masked_images.std(dim=(2, 3), keepdim=True).get_data()\n",
    "        images_max_clip = images_mean + self.hparams.clip_stds * images_std\n",
    "        images_min_clip = images_mean - self.hparams.clip_stds * images_std\n",
    "        images = (images - images_min_clip) / (images_max_clip - images_min_clip)\n",
    "        \n",
    "        # Data augmentation during training.\n",
    "        if self.trainer.training: \n",
    "            images = self.color_augmentation_pipeline(images)\n",
    "            images, masks = self.spatial_augmentation_pipeline(images, masks)\n",
    "        \n",
    "        batch['image'] = images\n",
    "        batch['mask'] = masks.squeeze(1).int()\n",
    "        return super().on_after_batch_transfer(batch, dataloader_idx)\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        x = batch['image']\n",
    "        # Do not propagate gradient to the encoder network for now.\n",
    "        with torch.no_grad():\n",
    "            features = self.model.encoder(x)\n",
    "        decoder_output = self.model.decoder(*features)\n",
    "\n",
    "        return self.model.segmentation_head(decoder_output)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx, *args: Any, **kwargs: Any) -> STEP_OUTPUT:\n",
    "        logits = self.forward(batch).squeeze()\n",
    "        loss = self.loss_criterion(logits, batch['mask'])\n",
    "        \n",
    "        # Update metrics\n",
    "        self.train_iou(logits, batch['mask'])\n",
    "        self.train_precision(logits, batch['mask'])\n",
    "        self.train_recall(logits, batch['mask'])\n",
    "        \n",
    "        # Log step loss\n",
    "        batch_size = batch['image'].shape[0]\n",
    "        self.log('train/loss', loss, on_epoch=True, on_step=True, batch_size=batch_size)\n",
    "        \n",
    "        # Log batch output (images)\n",
    "        if batch_idx == 0:\n",
    "            self.log_batch_output(batch, logits)\n",
    "            \n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        # Log metrics\n",
    "        self.log('train/iou', self.train_iou)\n",
    "        self.log('train/precision', self.train_precision)\n",
    "        self.log('train/recall', self.train_recall)\n",
    "        return super().on_train_epoch_end()\n",
    "    \n",
    "    def log_batch_output(self, batch, logits):\n",
    "        if isinstance(self.logger, TensorBoardLogger):\n",
    "            stage = 'none'\n",
    "            if self.trainer.validating:\n",
    "                stage = 'validation'\n",
    "            if self.trainer.training:\n",
    "                stage = 'train'\n",
    "            mask = batch['mask'].unsqueeze(1)\n",
    "            segmentation_mask = logits.unsqueeze(1) > self.hparams.logits_threshold\n",
    "            summary_writer: SummaryWriter = self.logger.experiment\n",
    "            summary_writer.add_images(f'{stage}/image', batch['image'], global_step=self.trainer.global_step)\n",
    "            summary_writer.add_images(f'{stage}/mask', mask * 255, global_step=self.trainer.global_step)\n",
    "            summary_writer.add_images(f'{stage}/logits', segmentation_mask, global_step=self.trainer.global_step)\n",
    "            \n",
    "            \n",
    "    # The same thing as the training step but on validation objects.\n",
    "    def validation_step(self, batch, batch_idx, *args: Any, **kwargs: Any) -> STEP_OUTPUT:\n",
    "        logits = self.forward(batch).squeeze()\n",
    "        loss = self.loss_criterion(logits, batch['mask'])\n",
    "        \n",
    "        self.validation_iou(logits, batch['mask'])\n",
    "        self.validation_precision(logits, batch['mask'])\n",
    "        self.validation_recall(logits, batch['mask'])\n",
    "        \n",
    "        self.validation_prec_rec_curve(logits, batch['mask'])\n",
    "        \n",
    "        batch_size = batch['image'].shape[0]\n",
    "        self.log('validation/loss', loss, on_epoch=True, batch_size=batch_size)\n",
    "        if batch_idx == 0:\n",
    "            self.log_batch_output(batch, logits)\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "    def on_validation_epoch_end(self) -> None:\n",
    "        self.log('validation/iou', self.validation_iou)\n",
    "        self.log('validation/precision', self.validation_precision)\n",
    "        self.log('validation/recall', self.validation_recall)\n",
    "        \n",
    "        # Log the precision recall curve!\n",
    "        if isinstance(self.logger, TensorBoardLogger):\n",
    "            summary_writer: SummaryWriter = self.logger.experiment\n",
    "            fig_, ax_ = self.validation_prec_rec_curve.plot(score=True)\n",
    "            summary_writer.add_figure('validation/prec_rec_curve', figure=fig_, global_step=self.trainer.global_step)\n",
    "            \n",
    "        return super().on_validation_epoch_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "model= PalaeochannelRGBExperimentModule.load_from_checkpoint(chkp)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction and metric calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the result\n",
    "def show_image_mask (image1,image2,image3):\n",
    "    # Create a figure and axes objects with 1 row and 3 columns\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(15, 5))\n",
    "\n",
    "    # Plot the first RGB image on the first subplot\n",
    "    image1 = reshape_as_image(image1)\n",
    "    axes[0].imshow(image1)\n",
    "    axes[0].set_title('Image')\n",
    "\n",
    "    # Plot the second binary image on the second subplot\n",
    "    image2 = reshape_as_image(image2)\n",
    "    axes[1].imshow(image2, cmap='gray')\n",
    "    axes[1].set_title('Mask')\n",
    "\n",
    "    # Plot the third binary image on the third subplot\n",
    "    axes[2].imshow(image3, cmap='gray')\n",
    "    axes[2].set_title('result')\n",
    "\n",
    "    image2=image2.squeeze()\n",
    "    \n",
    "\n",
    "    overlay_img= np.zeros((image2.shape[0], image2.shape[1], 3), dtype=np.uint8)\n",
    "    print('overlay',overlay_img.shape)\n",
    "    overlay_img[:,:,0]=image3*255 # put the result on red\n",
    "    overlay_img[:,:,1]=image2*255 # put the mask on green\n",
    "    print('min,max',overlay_img.min(),overlay_img.max())\n",
    "\n",
    "    # Plot the overlay_img\n",
    "    axes[3].imshow(overlay_img)\n",
    "    axes[3].set_title('overlay')\n",
    "\n",
    "\n",
    "    # Hide the axis ticks for all subplots\n",
    "    for ax in axes:\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(binary_image, mask): \n",
    "    # Calculate True Positives, False Positives, False Negatives\n",
    "    true_positives = np.logical_and(binary_image, mask).sum()\n",
    "    false_positives = np.logical_and(binary_image, np.logical_not(mask)).sum()\n",
    "    false_negatives = np.logical_and(np.logical_not(binary_image), mask).sum()\n",
    "\n",
    "    # Calculate Intersection over Union (IoU)\n",
    "    intersection = true_positives\n",
    "    union = true_positives + false_positives + false_negatives\n",
    "    iou = intersection / union if union > 0 else 0.0\n",
    "\n",
    "    # Calculate Recall\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0.0\n",
    "    \n",
    "    # Calculate Precision\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0.0\n",
    "    print('fp', false_positives,'fn',false_negatives)\n",
    "\n",
    "    # Calculate F1\n",
    "    f1 = 2*(precision*recall)/(precision+recall) if recall > 0 else 0.0\n",
    "    return iou, recall, precision, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_binary_image(binary_image, output_path, filename, mask_file_path):\n",
    "    \"\"\"\n",
    "    Saves a binary image as a georeferenced raster, taking georeferencing information from the mask file.\n",
    "    \n",
    "    Args:\n",
    "        binary_image (np.array): Binary image array (0 and 1 values).\n",
    "        output_path (str): Directory to save the output raster.\n",
    "        filename (str): Name of the output file.\n",
    "        mask_file_path (str): Path to the mask file used for georeferencing.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert the binary image array to uint8\n",
    "    binary_image_uint8 = (binary_image * 255).astype(np.uint8)\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    output_dir = Path(output_path)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Construct the full file path\n",
    "    file_path = output_dir / filename\n",
    "\n",
    "    # Open the original georeferenced image using Rasterio\n",
    "    with rio.open(mask_file_path) as mask_dataset:\n",
    "        if mask_dataset is None:\n",
    "            raise ValueError(f\"Could not open {mask_file_path} for georeferencing information.\")\n",
    "\n",
    "        # Retrieve geotransform and projection from the mask image\n",
    "        geotransform = mask_dataset.transform\n",
    "        projection = mask_dataset.crs\n",
    "\n",
    "    # Get image dimensions from the binary image\n",
    "    height, width = binary_image.shape\n",
    "\n",
    "    # Create a new georeferenced raster file\n",
    "    with rio.open(str(file_path), 'w', driver='GTiff', count=1, dtype='uint8', \n",
    "                       width=width, height=height, crs=projection, transform=geotransform, nodata=0) as output_dataset:\n",
    "        # Write the binary image to the new raster\n",
    "        output_dataset.write(binary_image_uint8, 1)\n",
    "        \n",
    "\n",
    "    print(f\"Saved georeferenced binary image: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_output (test_img,test_mask):\n",
    "    with rio.open(test_img) as src:\n",
    "        # Read the image as a numpy array\n",
    "        image = src.read()\n",
    "        # profile = src.profile\n",
    "        # crs = src.crs\n",
    "        # transform = src.transform\n",
    "\n",
    "    with rio.open(test_mask) as src:\n",
    "    # Read the image as a numpy array\n",
    "        mask = src.read()\n",
    "        # profile = src.profile\n",
    "        # crs = src.crs\n",
    "        # transform = src.transform\n",
    "\n",
    "    #normalization\n",
    "    clip_stds =2.5\n",
    "    image_mean = image.mean()\n",
    "    image_std = image.std()\n",
    "    image_max_clip = image_mean + clip_stds * image_std\n",
    "    image_min_clip = image_mean - clip_stds * image_std\n",
    "    test_image = (image - image_min_clip) / (image_max_clip - image_min_clip) #[0,1]\n",
    "\n",
    "    # change to tensor\n",
    "    tile_image_tensor = torch.from_numpy(test_image)\n",
    "    # set device\n",
    "    tile_image_test = tile_image_tensor.to(0)\n",
    "    tile_image_test = tile_image_test.float()\n",
    "\n",
    "    # get prediction\n",
    "    output= model(dict(image=tile_image_test.unsqueeze(0)))\n",
    "    \n",
    "    # activate function\n",
    "    output = F.sigmoid(output)\n",
    "    # Convert the tensor to a NumPy array and remove the batch dimension\n",
    "    image_array = output.squeeze().cpu().detach().numpy()\n",
    "    binary_image = (image_array > 0.5).astype(int)\n",
    "    # Plot the binary image using matplotlib\n",
    "    # plt.imshow(binary_image, cmap='binary')  # 'binary' colormap for binary images\n",
    "    # plt.show()\n",
    "    show_image_mask(image,mask,binary_image)\n",
    "\n",
    "   # Calculate metrics\n",
    "    iou, recall, precision, f1 = calculate_metrics(binary_image, mask)\n",
    "\n",
    "\n",
    "    print(\"IoU:\", iou)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"f1:\", f1)\n",
    "\n",
    "\n",
    "    return iou, recall, precision,f1, binary_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all files in the image folder\n",
    "img_file_names = sorted(os.listdir(test_img_folder))\n",
    "\n",
    "# Get a list of all files in the mask folder\n",
    "mask_file_names = sorted(os.listdir(test_mask_folder))\n",
    "\n",
    "iou_total, recall_total, precision_total, f1_total = 0.0, 0.0, 0.0, 0.0\n",
    "\n",
    "# Use zip to iterate over both lists simultaneously\n",
    "for img_file_name, mask_file_name in zip(img_file_names, mask_file_names):\n",
    "    img_file_path = os.path.join(test_img_folder, img_file_name)\n",
    "    mask_file_path = os.path.join(test_mask_folder, mask_file_name)\n",
    "    \n",
    "    # Calculate metrics for the current pair of images\n",
    "    iou, recall, precision, f1, binary_image = print_output(img_file_path, mask_file_path)\n",
    "    \n",
    "    # Accumulate metrics\n",
    "    iou_total += iou\n",
    "    recall_total += recall\n",
    "    precision_total += precision\n",
    "    f1_total+=f1\n",
    "    \n",
    "    print(\"Image File Path:\", img_file_path)\n",
    "    print(\"Mask File Path:\", mask_file_path)\n",
    "    print('iou', iou)\n",
    "    print('recall', recall)\n",
    "    print('precision', precision)\n",
    "    print('f1', f1)\n",
    "\n",
    "    # Save output using georeferencing from the mask\n",
    "    if save_output:\n",
    "        filename = 'result_' + img_file_name\n",
    "        save_binary_image(binary_image, output_path, filename, mask_file_path)\n",
    "      \n",
    "\n",
    "\n",
    "# Calculate averages\n",
    "num_files = len(img_file_names)\n",
    "average_iou = iou_total / num_files\n",
    "average_recall = recall_total / num_files\n",
    "average_precision = precision_total / num_files\n",
    "average_f1= f1_total/num_files\n",
    "\n",
    "print('Average IoU:', average_iou)\n",
    "print('Average Recall:', average_recall)\n",
    "print('Average Precision:', average_precision)\n",
    "print('Average F1:', average_f1)\n",
    "\n",
    "# Format the results into a string\n",
    "results_content = f\"\"\"Results Summary:\n",
    "---------------------\n",
    "Average IoU: {average_iou}\n",
    "Average Recall: {average_recall}\n",
    "Average Precision: {average_precision}\n",
    "Average F1:{average_f1}\n",
    "\"\"\"\n",
    "\n",
    "# Save to a text file\n",
    "results_file_path = images_path + month + \"results_summary.txt\"\n",
    "\n",
    "with open(results_file_path, \"w\") as results_file:\n",
    "    results_file.write(results_content)\n",
    "\n",
    "print(f\"Results saved to {results_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
